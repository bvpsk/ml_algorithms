{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, df, col_types, target_id = 0):\n",
    "        self.target_id = target_id\n",
    "        self.df = df\n",
    "        self.col_types = col_types\n",
    "        self.dictionaries = {}\n",
    "        self.reverses = {}\n",
    "        self.cols = list(df.columns)\n",
    "        for i in range(len(self.df.columns)):\n",
    "            if self.col_types[i] == \"nc\":\n",
    "                self.normalize(i)\n",
    "                \n",
    "    def normalize(self, col_idx):\n",
    "        col = self.df.values[:, col_idx]\n",
    "        name = self.df.columns[col_idx]\n",
    "        uniques = list(set(col))\n",
    "        dictionary = {unique : i for (i, unique) in enumerate(uniques)}\n",
    "        for i in range(len(col)):\n",
    "            self.df.at[i, name] = dictionary[col[i]]\n",
    "        self.dictionaries[col_idx] = dictionary\n",
    "        self.reverses[col_idx] = {value: key for (key, value) in dictionary.items()}\n",
    "        \n",
    "    def split(self, val):\n",
    "        xs = [i for i in range(len(self.cols)) if i != self.target_id]\n",
    "        self.X = self.df.iloc[:, xs].values\n",
    "        self.y = self.df.iloc[:, self.target_id].values\n",
    "        self.y = self.y.astype('int')\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = val, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset # Instance of our Dataset class\n",
    "        self.target = dataset.cols[dataset.target_id] # name of the target column\n",
    "        self.hierarchical_likelihoods = {}\n",
    "        self.priors = {}\n",
    "        self.total = dataset.df.shape[0] * 1.0 # total no. of rows in our dataset\n",
    "\n",
    "    def calculate_likelihoods(self):\n",
    "        # calculation of mean and variance for continuous variables\n",
    "        self.means = dataset.df.groupby(self.target).mean()\n",
    "        self.variances = dataset.df.groupby(self.target).var()\n",
    "        \n",
    "        # calculation of likelihoods for discrete variables\n",
    "        self.hierarchical_likelihoods = {} # target level hierarchy\n",
    "        for target, idx in dataset.dictionaries[dataset.target_id].items():\n",
    "            # loop through all possible target classes\n",
    "            sample = dataset.df[dataset.df[dataset.cols[dataset.target_id]] == idx]\n",
    "            # All rows in the sample contains only one target class\n",
    "            self.priors[idx] = sample.shape[0]*1.0\n",
    "            \n",
    "            class_wise_probs = {} #column level hierarchy\n",
    "            for i, col in enumerate(dataset.cols):\n",
    "                # loop through all available columns and calculate likelihoods\n",
    "                if i == dataset.target_id or dataset.col_types[i] == 'c':\n",
    "                    # Skip this column if it is a continuous variable or a target variable\n",
    "                    continue\n",
    "                    \n",
    "                uniques = {} #class level hierarchy\n",
    "                for unique, u_idx in dataset.dictionaries[i].items():\n",
    "                    # for every unique value in the column calculate likelihoods\n",
    "                    count = sample[sample[col] == u_idx].shape[0]\n",
    "                    uniques[u_idx] = count/self.priors[idx]\n",
    "                \n",
    "                #save class level hierarchies in column level hierarchies\n",
    "                class_wise_probs[i] = uniques\n",
    "                \n",
    "            #save column level hierarchies in target level hierarchies\n",
    "            self.hierarchical_likelihoods[idx] = class_wise_probs\n",
    "            \n",
    "            self.priors[idx] /= self.total\n",
    "    def likelihood(self, target_idx, col_idx, val):\n",
    "        if dataset.col_types[col_idx] == 'nc':\n",
    "            # when the column is a discrete variable, return the\n",
    "            # likelihood from hierarchical_likelihoods\n",
    "            return self.hierarchical_likelihoods[target_idx][col_idx][val]\n",
    "        else:\n",
    "            # If continuous, calculate the likelihood using gaussian formula\n",
    "            m = self.means[dataset.cols[col_idx]][target_idx]\n",
    "            v = self.variances[dataset.cols[col_idx]][target_idx]\n",
    "            likelihood = 1/(np.sqrt(2*np.pi*v)) * np.exp((-(val-m)**2)/(2*v))\n",
    "            return likelihood\n",
    "    def predict(self, x):\n",
    "        arr = [] #empty array to store outputs\n",
    "        num_cols = x.shape[1] #total no. of features in input data\n",
    "        for i in range(x.shape[0]): #iterating through all inputs(rows)\n",
    "            posteriors = {} # dictionary of all available posteriors\n",
    "            for idx, target in dataset.reverses[dataset.target_id].items(): \n",
    "                #iterating through every target class\n",
    "                prob = self.priors[idx] #initializing running product of likelihoods\n",
    "\n",
    "                for j in range(num_cols):\n",
    "                    # iterate through every feature in our input\n",
    "                    prob *= self.likelihood(idx, j, x[i][j]) #accumulate the product of likelihoods\n",
    "                posteriors[idx] = prob # store the probability as posterior of this target class\n",
    "            #sort the posteriors and select the one with highest probability\n",
    "            prediction = sorted(posteriors.items(), key = lambda x: x[1])[-1][0]\n",
    "            arr.append(prediction) #save this prediction for this row\n",
    "        return np.asarray(arr) #return the array as a numpy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the dataset from here\n",
    "#https://www.kaggle.com/abcsds/pokemon\n",
    "# and place it in the same folder\n",
    "df = pd.read_csv('Pokemon.csv')\n",
    "df = df.drop(['#', 'Name'], axis = 1)\n",
    "df = df.fillna(0)\n",
    "col_types = {i : 'c' for i in range(len(df.columns))}\n",
    "col_types[0] = \"nc\"\n",
    "col_types[1] = \"nc\"\n",
    "col_types[9] = \"nc\"\n",
    "col_types[10] = \"nc\"\n",
    "dataset = Dataset(df, col_types, target_id = 10)\n",
    "dataset.split(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Naive Bayes Algorithm written from scratch : 93.333\n"
     ]
    }
   ],
   "source": [
    "nbc = NaiveBayesClassifier(dataset)\n",
    "nbc.calculate_likelihoods()\n",
    "y_pred = nbc.predict(dataset.X_test)\n",
    "accuracy = accuracy_score(dataset.y_test, y_pred)*100\n",
    "print(f'Accuracy of Gaussian Naive Bayes Algorithm written from scratch : {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Naive Bayes Algorithm from SKLearn(using python module) : 92.917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(dataset.X_train, dataset.y_train)\n",
    "y_pred = classifier.predict(dataset.X_test)\n",
    "accuracy = accuracy_score(dataset.y_test, y_pred)*100\n",
    "print(f'Accuracy of Gaussian Naive Bayes Algorithm from SKLearn(using python module) : {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
